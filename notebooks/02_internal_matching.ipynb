{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO_vYnHwU6HK"
      },
      "source": [
        "# cell 1 - cài thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UjK3Ej8zSKYC"
      },
      "outputs": [],
      "source": [
        "!pip install -q pymupdf pdfplumber sentence-transformers python-docx\n",
        "!pip install -q scikit-learn beautifulsoup4 requests nltk\n",
        "!pip install --no-deps -q googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show python-docx\n",
        "!pip show pdfplumber\n",
        "!pip show sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGDoiTDe7YkC",
        "outputId": "8e21952e-c347-44a9-ef72-6083816644a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: python-docx\n",
            "Version: 1.2.0\n",
            "Summary: Create, read, and update Microsoft Word .docx files.\n",
            "Home-page: https://github.com/python-openxml/python-docx\n",
            "Author: \n",
            "Author-email: Steve Canny <stcanny@gmail.com>\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: lxml, typing_extensions\n",
            "Required-by: \n",
            "Name: pdfplumber\n",
            "Version: 0.11.9\n",
            "Summary: Plumb a PDF for detailed information about each char, rectangle, and line.\n",
            "Home-page: https://github.com/jsvine/pdfplumber\n",
            "Author: Jeremy Singer-Vine\n",
            "Author-email: jsvine@gmail.com\n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: pdfminer.six, Pillow, pypdfium2\n",
            "Required-by: \n",
            "Name: sentence-transformers\n",
            "Version: 5.2.0\n",
            "Summary: Embeddings, Retrieval, and Reranking\n",
            "Home-page: https://www.SBERT.net\n",
            "Author: \n",
            "Author-email: Nils Reimers <info@nils-reimers.de>, Tom Aarsen <tom.aarsen@huggingface.co>\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: huggingface-hub, scikit-learn, scipy, torch, tqdm, transformers, typing_extensions\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPnkMAd6VFgS"
      },
      "source": [
        "# cell 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T42MnKPgSdpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb4d6334-d566-499b-f8c5-4e2664b44c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython', '/tmp/tmpotrvf9my']\n",
            "Loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.path)\n",
        "\n",
        "import nltk\n",
        "import pdfplumber\n",
        "import requests\n",
        "from docx import Document\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download(\"punkt_tab\", quiet=True)\n",
        "\n",
        "model = SentenceTransformer(\"sentence-transformers/LaBSE\")\n",
        "\n",
        "print(\"Loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwqHqq7zVVsc"
      },
      "source": [
        "# cell 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uMUZiOFBShNO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9f7042-7222-4bfb-a690-18abaa502bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Functions defined OK\n"
          ]
        }
      ],
      "source": [
        "def read_pdf(path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            if page.extract_text():\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "def read_docx(path):\n",
        "    doc = Document(path)\n",
        "    return \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n",
        "\n",
        "print(\"Functions defined OK\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cell 4"
      ],
      "metadata": {
        "id": "hA4f6B25KfBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# --- CẤU HÌNH & LOAD MODEL ---\n",
        "try:\n",
        "    model = SentenceTransformer('sentence-transformers/LaBSE')\n",
        "    print(\"Load model thành công.\")\n",
        "except Exception as e:\n",
        "    print(f\"Không load được model: {e}\")\n",
        "    model = None\n",
        "\n",
        "\n",
        "def read_text_file(file_path):\n",
        "    \"\"\"Đọc nội dung file text, trả về chuỗi rỗng nếu lỗi.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return f.read().strip()\n",
        "    except:\n",
        "        return \"\"\n",
        "\n",
        "def find_best_match_labse(source_query, target_folder, model, top_k=3):\n",
        "    \"\"\"\n",
        "    Tìm top_k file trong target_folder có nội dung tương đồng nhất với source_query.\n",
        "    \"\"\"\n",
        "    if model is None: return []\n",
        "\n",
        "    # 1. Embed query\n",
        "    query_emb = model.encode(str(source_query)[:1000], convert_to_tensor=True)\n",
        "\n",
        "    # 2. Lấy danh sách file\n",
        "    files = glob.glob(os.path.join(target_folder, \"**/*.txt\"), recursive=True)\n",
        "    if not files:\n",
        "        print(f\"Thư mục '{target_folder}' trống.\")\n",
        "        return []\n",
        "\n",
        "    results = []\n",
        "    print(f\"DEBUG: Đang so khớp với {len(files)} file...\")\n",
        "\n",
        "    # 3. Tính similarity từng file\n",
        "    for path in files:\n",
        "        content = read_text_file(path)\n",
        "        if len(content) < 10: continue # Bỏ qua file quá ngắn\n",
        "\n",
        "        target_emb = model.encode(content[:1000], convert_to_tensor=True)\n",
        "        score = util.pytorch_cos_sim(query_emb, target_emb).item()\n",
        "        results.append((score, path))\n",
        "\n",
        "    # 4. Sort & return\n",
        "    results.sort(key=lambda x: x[0], reverse=True)\n",
        "    return results[:top_k]\n",
        "\n",
        "# --- UNIT TEST ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n--- TEST MODULE: INTERNAL MATCHING ---\")\n",
        "\n",
        "    # Tạo dữ liệu giả để test logic (Tự động tạo folder và file test)\n",
        "    test_dir = \"temp_test_data\"\n",
        "    if not os.path.exists(test_dir):\n",
        "        os.makedirs(test_dir)\n",
        "        # Tạo 2 file mẫu: 1 file Lịch sử (khớp), 1 file Khoa học (không khớp)\n",
        "        with open(f\"{test_dir}/doc_history.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"Năm 968, Đinh Bộ Lĩnh lên ngôi Hoàng đế, đặt tên nước là Đại Cồ Việt.\")\n",
        "        with open(f\"{test_dir}/doc_science.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"Nước (H2O) là hợp chất hóa học của oxy và hydro.\")\n",
        "\n",
        "    # Chạy thử hàm tìm kiếm\n",
        "    query = \"Đinh Tiên Hoàng dẹp loạn 12 sứ quân\"\n",
        "    print(f\"Input Query: '{query}'\")\n",
        "\n",
        "    if model:\n",
        "        matches = find_best_match_labse(query, test_dir, model)\n",
        "        print(\"\\nKết quả tìm kiếm:\")\n",
        "        for score, path in matches:\n",
        "            print(f\"  - File: {os.path.basename(path)} | Score: {score:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "669y5boVKc-3",
        "outputId": "ba7b688c-e420-4837-c5a2-1082106a88ff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load model thành công.\n",
            "\n",
            "--- TEST MODULE: INTERNAL MATCHING ---\n",
            "Input Query: 'Đinh Tiên Hoàng dẹp loạn 12 sứ quân'\n",
            "DEBUG: Đang so khớp với 2 file...\n",
            "\n",
            "Kết quả tìm kiếm:\n",
            "  - File: doc_history.txt | Score: 0.3240\n",
            "  - File: doc_science.txt | Score: 0.1894\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}